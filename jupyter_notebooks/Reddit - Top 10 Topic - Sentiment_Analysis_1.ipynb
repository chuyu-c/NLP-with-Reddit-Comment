{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark NLP\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.3.2\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.eventLog.enabled', 'true'),\n",
       " ('spark.dynamicAllocation.minExecutors', '1'),\n",
       " ('spark.sql.warehouse.dir', 'file:/spark-warehouse'),\n",
       " ('spark.history.fs.logDirectory',\n",
       "  'gs://dataproc-temp-us-central1-84427460872-fixxspuh/97cd0fe0-90c7-4b68-ba8a-fcc718886ab3/spark-job-history'),\n",
       " ('spark.executor.memory', '5g'),\n",
       " ('spark.driver.host',\n",
       "  'cluster-e4d0-m.us-central1-b.c.big-data-platforms-329618.internal'),\n",
       " ('spark.yarn.am.memory', '640m'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.app.startTime', '1638388665963'),\n",
       " ('spark.executor.instances', '2'),\n",
       " ('spark.driver.memory', '8g'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.yarn.unmanagedAM.enabled', 'true'),\n",
       " ('spark.sql.autoBroadcastJoinThreshold', '43m'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.port', '37961'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.driver.appUIAddress',\n",
       "  'http://cluster-e4d0-m.us-central1-b.c.big-data-platforms-329618.internal:35033'),\n",
       " ('spark.sql.cbo.joinReorder.enabled', 'true'),\n",
       " ('spark.driver.maxResultSize', '1920m'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://cluster-e4d0-m:8088/proxy/application_1638310962676_0011'),\n",
       " ('spark.scheduler.mode', 'FAIR'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'cluster-e4d0-m'),\n",
       " ('spark.sql.adaptive.enabled', 'true'),\n",
       " ('spark.yarn.jars', 'local:/usr/lib/spark/jars/*'),\n",
       " ('spark.app.id', 'application_1638310962676_0011'),\n",
       " ('spark.scheduler.minRegisteredResourcesRatio', '0.0'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.hadoop.hive.execution.engine', 'mr'),\n",
       " ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'),\n",
       " ('spark.dynamicAllocation.maxExecutors', '10000'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.ui.port', '0'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/usr/lib/spark/python/lib/py4j-0.10.9-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip'),\n",
       " ('spark.app.name', 'Spark Updated Conf'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.eventLog.dir',\n",
       "  'gs://dataproc-temp-us-central1-84427460872-fixxspuh/97cd0fe0-90c7-4b68-ba8a-fcc718886ab3/spark-job-history'),\n",
       " ('spark.rpc.message.maxSize', '512'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1638310962676_0011'),\n",
       " ('spark.yarn.historyServer.address', 'cluster-e4d0-m:18080'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.history.fs.gs.outputstream.type', 'BASIC'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.sql.cbo.enabled', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create Spark session\n",
    "spark = SparkSession.builder.appName('RedditComments').getOrCreate()\n",
    "\n",
    "#change configuration settings on Spark \n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','8g')])\n",
    "\n",
    "#print spark configuration settings\n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 19:57:55 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \n",
      "java.lang.InterruptedException\n",
      "\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n",
      "\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n",
      "\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n",
      "\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"delimiter\",\",\") \\\n",
    "    .option(\"multiLine\",\"true\") \\\n",
    "    .option(\"quote\", \"\\\"\")  \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\",True) \\\n",
    "    .csv(\"gs://reddit-data-team-1/data_cleaned.csv\",inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- body: string (nullable = true)\n",
      " |-- clean_comment: string (nullable = true)\n",
      " |-- category: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[body: string, clean_comment: string, category: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-------------------+\n",
      "|summary|                body|       clean_comment|           category|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "|  count|             4864687|             4849322|            4864688|\n",
      "|   mean|            Infinity|                 NaN|0.18691332311548037|\n",
      "| stddev|                 NaN|                 NaN| 0.7967911112011219|\n",
      "|    min|\t\"Mother's Little...|\tnow playing\n",
      "mumf...|                 -1|\n",
      "|    25%|              3820.0|              1999.0|                  0|\n",
      "|    50%|              6790.0|              5670.0|                  0|\n",
      "|    75%|              9837.0|              9164.0|                  1|\n",
      "|    max|                  ðŸ›ƒ|ï¿½ï¿½\u0006ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½...|                  1|\n",
      "+-------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('body', 'string'), ('clean_comment', 'string'), ('category', 'int')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|category|  count|\n",
      "+--------+-------+\n",
      "|       1|2083852|\n",
      "|       0|1606259|\n",
      "|      -1|1174577|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data.groupBy(\"category\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|category|  count|\n",
      "+--------+-------+\n",
      "|       1|2083852|\n",
      "|       0|1606259|\n",
      "|      -1|1174577|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "data.groupBy(\"category\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+\n",
      "|                body|       clean_comment|category|\n",
      "+--------------------+--------------------+--------+\n",
      "|gg this one's ove...|gg this one's ove...|       0|\n",
      "|No one has a Euro...|No one has a Euro...|       0|\n",
      "|That the kid \"..r...|That the kid \"..r...|      -1|\n",
      "|                NSFL|                NSFL|       0|\n",
      "|Get back to your ...|Get back to your ...|       0|\n",
      "+--------------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumn(\"clean_comment\",regexp_replace(col('body'), '\\d+', ''))\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim, col, lower\n",
    "def removePunctuation(column):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        column (Column): A Column containing a sentence.\n",
    "\n",
    "    Returns:\n",
    "        Column: A Column named 'sentence' with clean-up operations applied.\n",
    "    \"\"\"\n",
    "    return trim(lower(regexp_replace(column, '[^\\sa-zA-Z0-9]', ''))).alias('sentence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.withColumn(\"cleaned\",removePunctuation(col('clean_comment')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------------------+\n",
      "|                body|       clean_comment|category|             cleaned|\n",
      "+--------------------+--------------------+--------+--------------------+\n",
      "|gg this one's ove...|gg this one's ove...|       0|gg this ones over...|\n",
      "|No one has a Euro...|No one has a Euro...|       0|no one has a euro...|\n",
      "+--------------------+--------------------+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4864688"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4864687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"cleaned\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "\n",
    "# stop words\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \n",
    "#add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\",'narendra','modi','...','â€œ','â€','â€™','â€¦','modiâ€™'] \n",
    "\n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "\n",
    "# bag of words count\n",
    "#countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=15000, minDF=5)\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 20:15:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|                body|       clean_comment|category|             cleaned|               words|            filtered|            features|label|\n",
      "+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|gg this one's ove...|gg this one's ove...|       0|gg this ones over...|[gg, this, ones, ...|[gg, this, ones, ...|(262144,[0,2,14,1...|  1.0|\n",
      "|No one has a Euro...|No one has a Euro...|       0|no one has a euro...|[no, one, has, a,...|[no, one, has, a,...|(262144,[1,7,12,1...|  1.0|\n",
      "|That the kid \"..r...|That the kid \"..r...|      -1|that the kid remi...|[that, the, kid, ...|[that, kid, remin...|(262144,[4,5,28,3...|  2.0|\n",
      "|                NSFL|                NSFL|       0|                nsfl|              [nsfl]|              [nsfl]|(262144,[13710],[...|  1.0|\n",
      "|Get back to your ...|Get back to your ...|       0|get back to your ...|[get, back, to, y...|[get, back, to, y...|(262144,[0,31,44,...|  1.0|\n",
      "+--------------------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "dataset.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition Training & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 20:16:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3891654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 20:25:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "[Stage 41:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Count: 973033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "Logistic Regression using Count Vector Features\n",
    "\n",
    "Our model will make predictions and score on the test set; we then look at the top 10 predictions from the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 20:35:31 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:45:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:55:36 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/12/01 20:55:37 WARN com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "21/12/01 20:55:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:55:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:56:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:56:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:56:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:56:35 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:56:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:56:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:57:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:57:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:57:33 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:57:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:58:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:58:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:58:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:58:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:58:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:59:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:59:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "21/12/01 20:59:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "# predictions.filter(predictions['prediction'] == 0).select(\"clean_text\",\"category\",\"probability\",\"label\",\"prediction\")\\\n",
    "# .orderBy(\"probability\", ascending=False).show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/01 20:59:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.4 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7704587422225653"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = dataset.randomSplit([0.8, 0.2], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"clean_text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7288555668318899"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "nbModel = nb.fit(trainingData)\n",
    "predictions = nbModel.transform(testData)\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"clean_text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7347902005300311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "nbAccuracy = evaluator.evaluate(predictions)\n",
    "print(nbAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
    "dtModel = dt.fit(trainingData)\n",
    "predictions = dtModel.transform(testData)\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"clean_text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4305849554692257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "dtAccuracy = evaluator.evaluate(predictions)\n",
    "print(dtAccuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/02 01:31:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1059.5 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"clean_text\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "#     .orderBy(\"probability\", ascending=False) \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2570274066280338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "rfAccuracy = evaluator.evaluate(predictions)\n",
    "print(rfAccuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OnevsRest classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 159:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "\n",
    "ovrModel = ovr.fit(trainingData)\n",
    "\n",
    "# score the model on test data.\n",
    "predictions = ovrModel.transform(testData)\n",
    "\n",
    "# predictions.filter(predictions['prediction'] == 0) \\\n",
    "#     .select(\"clean_text\",\"category\",\"label\",\"prediction\") \\\n",
    "#     .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "ovrAccuracy = evaluator.evaluate(predictions)\n",
    "print(ovrAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "model = ['Logistic regression', 'Naive Bayes', 'Random Forest', 'OneVsRest']\n",
    "accuracy = [lrAccuracy,nbAccuracy,rfAccuracy, ovrAccuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_x():\n",
    "    # this is for plotting purpose\n",
    "    index = np.arange(len(model))\n",
    "    plt.bar(index, accuracy)\n",
    "    plt.xlabel('models', fontsize=10)\n",
    "    plt.ylabel('prediction accuracy', fontsize=10)\n",
    "    plt.xticks(index, model, fontsize=10, rotation=30)\n",
    "    plt.title('Accuracy of each model')\n",
    "    plt.show()\n",
    "    \n",
    "plot_bar_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
